{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1d06512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4f23291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Data (NASA C-MAPSS dataset)\n",
    "train_data_fd001 = pd.read_csv('CMAPSSData/train_FD001.txt', header=None, delimiter=' ')\n",
    "train_data_fd002 = pd.read_csv('CMAPSSData/train_FD002.txt', header=None, delimiter=' ')\n",
    "train_data_fd003 = pd.read_csv('CMAPSSData/train_FD003.txt', header=None, delimiter=' ')\n",
    "train_data_fd004 = pd.read_csv('CMAPSSData/train_FD004.txt', header=None, delimiter=' ')\n",
    "\n",
    "test_data_fd001 = pd.read_csv('CMAPSSData/test_FD001.txt', header=None, delimiter=' ')\n",
    "test_data_fd002 = pd.read_csv('CMAPSSData/test_FD002.txt', header=None, delimiter=' ')\n",
    "test_data_fd003 = pd.read_csv('CMAPSSData/test_FD003.txt', header=None, delimiter=' ')\n",
    "test_data_fd004 = pd.read_csv('CMAPSSData/test_FD004.txt', header=None, delimiter=' ')\n",
    "\n",
    "rul_data_fd001 = pd.read_csv('CMAPSSData/RUL_FD001.txt', header=None, delimiter=',')\n",
    "rul_data_fd002 = pd.read_csv('CMAPSSData/RUL_FD002.txt', header=None, delimiter=',')\n",
    "rul_data_fd003 = pd.read_csv('CMAPSSData/RUL_FD003.txt', header=None, delimiter=',')\n",
    "rul_data_fd004 = pd.read_csv('CMAPSSData/RUL_FD004.txt', header=None, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c752ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dataset_id(df, dataset_name):\n",
    "    df['dataset_id'] = dataset_name\n",
    "    return df\n",
    "\n",
    "# Processing training data\n",
    "train_data_fd001 = add_dataset_id(train_data_fd001, 'FD001')\n",
    "train_data_fd002 = add_dataset_id(train_data_fd002, 'FD002')\n",
    "train_data_fd003 = add_dataset_id(train_data_fd003, 'FD003')\n",
    "train_data_fd004 = add_dataset_id(train_data_fd004, 'FD004')\n",
    "\n",
    "# Processing test data\n",
    "test_data_fd001 = add_dataset_id(test_data_fd001, 'FD001')\n",
    "test_data_fd002 = add_dataset_id(test_data_fd002, 'FD002')\n",
    "test_data_fd003 = add_dataset_id(test_data_fd003, 'FD003')\n",
    "test_data_fd004 = add_dataset_id(test_data_fd004, 'FD004')\n",
    "\n",
    "# Combining all the data\n",
    "train_data = pd.concat([train_data_fd001, train_data_fd002, train_data_fd003, train_data_fd004], axis=0, ignore_index=True)\n",
    "test_data = pd.concat([test_data_fd001, test_data_fd002, test_data_fd003, test_data_fd004], axis=0, ignore_index=True)\n",
    "rul_data = pd.concat([rul_data_fd001, rul_data_fd002, rul_data_fd003, rul_data_fd004], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853a6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning and Preprocessing\n",
    "train_data.drop(columns=[26, 27], inplace=True)\n",
    "test_data.drop(columns=[26, 27], inplace=True)\n",
    "\n",
    "column_names = [\"unit_number\",\"time_in_cycles\",\"operational_set_1\",\"operational_set_2\",\"operational_set_3\",\n",
    "                \"T2\",\"T24\",\"T30\",\"T50\",\"P2\",\"P15\",\"P30\",\"Nf\",\"Nc\",\"epr\",\"Ps30\",\"phi\",\"NRf\",\"NRc\",\"BPR\",\"farB\",\"htBleed\",\n",
    "                \"Nf_dmd\",\"PCNfR_dmd\",\"W31\",\"W32\", 'dataset_id']\n",
    "train_data.columns = column_names\n",
    "test_data.columns = column_names\n",
    "rul_data.columns = ['RUL']\n",
    "\n",
    "# Filling missing values\n",
    "train_data.fillna(train_data.mean(), inplace=True)\n",
    "test_data.fillna(test_data.mean(), inplace=True)\n",
    "\n",
    "# Calculate Remaining Useful Life (RUL)\n",
    "train_data['RUL'] = train_data.groupby('unit_number')['time_in_cycles'].transform(max) - train_data['time_in_cycles']\n",
    "train_data = pd.merge(train_data, rul_data, how='left', left_on='unit_number', right_index=True)\n",
    "train_data['RUL'] = train_data[['RUL_x', 'RUL_y']].min(axis=1)\n",
    "train_data.drop(columns=['RUL_x', 'RUL_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8129108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering (Time-series Features)\n",
    "def create_time_series_features(df):\n",
    "    df['lag_1'] = df['RUL'].shift(1)\n",
    "    df['rolling_mean_3'] = df['RUL'].rolling(3).mean()\n",
    "    df['rolling_std_3'] = df['RUL'].rolling(3).std()\n",
    "    df['rolling_mean_5'] = df['RUL'].rolling(5).mean()\n",
    "    df['rolling_std_5'] = df['RUL'].rolling(5).std()\n",
    "    return df\n",
    "\n",
    "train_data = create_time_series_features(train_data)\n",
    "train_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb5e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Features and Target\n",
    "X = train_data.drop(['unit_number', 'time_in_cycles', 'RUL'], axis=1)\n",
    "y = train_data['RUL']\n",
    "\n",
    "# One-hot encode the dataset_id to treat it as a categorical variable\n",
    "X = pd.get_dummies(X, columns=['dataset_id'], drop_first=True)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9026dc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 1.6275143536528833\n",
      "Random Forest RMSE: 1.2846103080999807\n",
      "XGBoost RMSE: 0.9753202381995089\n",
      "CatBoost RMSE: 0.7472865908091163\n"
     ]
    }
   ],
   "source": [
    "# Model Training (Linear Regression, Random Forest, XGBoost, CatBoost)\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"Linear Regression RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lr)))\n",
    "\n",
    "# 2. Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_rf)))\n",
    "\n",
    "# 3. XGBoost\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"XGBoost RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_xgb)))\n",
    "\n",
    "# 4. CatBoost\n",
    "catboost_model = CatBoostRegressor(learning_rate=0.05, iterations=1000, depth=10, verbose=0)\n",
    "catboost_model.fit(X_train, y_train)\n",
    "y_pred_catboost = catboost_model.predict(X_test)\n",
    "print(\"CatBoost RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_catboost)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc1067c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted RMSE values (Best models first):\n",
      "CatBoost: 0.7472865908091163\n",
      "XGBoost: 0.9753202381995089\n",
      "Random Forest: 1.2846103080999807\n",
      "Linear Regression: 1.6275143536528833\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "rmse_values = {\n",
    "    'Linear Regression': np.sqrt(mean_squared_error(y_test, y_pred_lr)),\n",
    "    'Random Forest': np.sqrt(mean_squared_error(y_test, y_pred_rf)),\n",
    "    'XGBoost': np.sqrt(mean_squared_error(y_test, y_pred_xgb)),\n",
    "    'CatBoost': np.sqrt(mean_squared_error(y_test, y_pred_catboost))\n",
    "}\n",
    "\n",
    "# Sorting RMSE values to get the best models\n",
    "sorted_rmse = sorted(rmse_values.items(), key=lambda x: x[1])\n",
    "print(\"Sorted RMSE values (Best models first):\")\n",
    "for model, rmse in sorted_rmse:\n",
    "    print(f\"{model}: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9f5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a list of models for stacking\n",
    "base_learners = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=100)),\n",
    "    ('xgb', xgb.XGBRegressor()),\n",
    "    ('catboost', CatBoostRegressor(learning_rate=0.05, iterations=1000, depth=10, verbose=0)),\n",
    "]\n",
    "meta_learner = LinearRegression()\n",
    "\n",
    "stacking_model = StackingRegressor(estimators=base_learners, final_estimator=meta_learner)\n",
    "stacking_model.fit(X_train, y_train)\n",
    "y_pred_stacking = stacking_model.predict(X_test)\n",
    "print(\"Stacking RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_stacking)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b407ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Comparison Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "models = [model for model, _ in sorted_rmse]\n",
    "rmse_vals = [rmse for _, rmse in sorted_rmse]\n",
    "plt.bar(models, rmse_vals, color='skyblue')\n",
    "plt.title('Model Comparison: RMSE for RUL Prediction')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b2a372",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4009/4009 [==============================] - 15s 3ms/step - loss: 2090.9448 - val_loss: 500.4193\n",
      "Epoch 2/50\n",
      "4009/4009 [==============================] - 12s 3ms/step - loss: 242.6861 - val_loss: 61.7653\n",
      "Epoch 3/50\n",
      "4009/4009 [==============================] - 12s 3ms/step - loss: 85.3050 - val_loss: 16.8129\n",
      "Epoch 4/50\n",
      "4009/4009 [==============================] - 11s 3ms/step - loss: 63.7308 - val_loss: 9.7271\n",
      "Epoch 5/50\n",
      "4009/4009 [==============================] - 11s 3ms/step - loss: 55.7687 - val_loss: 7.3351\n",
      "Epoch 6/50\n",
      "4009/4009 [==============================] - 11s 3ms/step - loss: 51.6906 - val_loss: 5.8744\n",
      "Epoch 7/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 48.2748 - val_loss: 5.5507\n",
      "Epoch 8/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 45.6944 - val_loss: 4.2199\n",
      "Epoch 9/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 43.5129 - val_loss: 3.3266\n",
      "Epoch 10/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 41.8080 - val_loss: 4.6008\n",
      "Epoch 11/50\n",
      "4009/4009 [==============================] - 12s 3ms/step - loss: 40.5764 - val_loss: 2.5804\n",
      "Epoch 12/50\n",
      "4009/4009 [==============================] - 12s 3ms/step - loss: 38.1950 - val_loss: 3.0716\n",
      "Epoch 13/50\n",
      "4009/4009 [==============================] - 12s 3ms/step - loss: 38.0257 - val_loss: 2.9391\n",
      "Epoch 14/50\n",
      "4009/4009 [==============================] - 12s 3ms/step - loss: 36.2664 - val_loss: 2.0212\n",
      "Epoch 15/50\n",
      "4009/4009 [==============================] - 12s 3ms/step - loss: 35.5259 - val_loss: 2.9222\n",
      "Epoch 16/50\n",
      "4009/4009 [==============================] - 12s 3ms/step - loss: 34.6322 - val_loss: 2.0866\n",
      "Epoch 17/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 33.8696 - val_loss: 2.8739\n",
      "Epoch 18/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 32.2995 - val_loss: 3.5272\n",
      "Epoch 19/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 31.7654 - val_loss: 2.7011\n",
      "Epoch 20/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 30.8484 - val_loss: 2.0932\n",
      "Epoch 21/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 30.3336 - val_loss: 1.5741\n",
      "Epoch 22/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 28.9866 - val_loss: 1.7552\n",
      "Epoch 23/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 28.9719 - val_loss: 1.4701\n",
      "Epoch 24/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 28.2093 - val_loss: 1.3548\n",
      "Epoch 25/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 27.4473 - val_loss: 1.1756\n",
      "Epoch 26/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 26.8085 - val_loss: 2.0503\n",
      "Epoch 27/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 26.4481 - val_loss: 1.9095\n",
      "Epoch 28/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 25.3913 - val_loss: 1.8494\n",
      "Epoch 29/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 25.4859 - val_loss: 1.3074\n",
      "Epoch 30/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 25.0054 - val_loss: 1.6090\n",
      "Epoch 31/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 24.3387 - val_loss: 1.1319\n",
      "Epoch 32/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 23.9296 - val_loss: 1.9891\n",
      "Epoch 33/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 23.8090 - val_loss: 1.1317\n",
      "Epoch 34/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 23.4046 - val_loss: 1.5660\n",
      "Epoch 35/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 22.5447 - val_loss: 1.2720\n",
      "Epoch 36/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 22.1628 - val_loss: 1.3102\n",
      "Epoch 37/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 22.1947 - val_loss: 1.4490\n",
      "Epoch 38/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 22.2006 - val_loss: 1.5319\n",
      "Epoch 39/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 21.6767 - val_loss: 2.6712\n",
      "Epoch 40/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 21.4213 - val_loss: 1.7249\n",
      "Epoch 41/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 20.8738 - val_loss: 1.1816\n",
      "Epoch 42/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 21.0957 - val_loss: 5.8124\n",
      "Epoch 43/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 20.7540 - val_loss: 1.4475\n",
      "Epoch 44/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 20.4868 - val_loss: 1.4977\n",
      "Epoch 45/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 20.4739 - val_loss: 1.3155\n",
      "Epoch 46/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 19.9331 - val_loss: 1.1858\n",
      "Epoch 47/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 19.8565 - val_loss: 1.3496\n",
      "Epoch 48/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 19.9896 - val_loss: 1.7685\n",
      "Epoch 49/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 19.7053 - val_loss: 1.3102\n",
      "Epoch 50/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 19.5416 - val_loss: 2.0068\n",
      "1003/1003 [==============================] - 2s 1ms/step\n",
      "LSTM RMSE: 1.416614160081982\n"
     ]
    }
   ],
   "source": [
    "# Reshape data for LSTM (samples, timesteps, features)\n",
    "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(LSTM(units=32, return_sequences=False))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "\n",
    "lstm_model.fit(X_train_lstm, y_train, epochs=50, batch_size=32, validation_data=(X_test_lstm, y_test))\n",
    "\n",
    "# Predicting with the LSTM\n",
    "y_pred_lstm = lstm_model.predict(X_test_lstm)\n",
    "print(\"LSTM RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lstm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e0664d0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4009/4009 [==============================] - 16s 3ms/step - loss: 1619.3101 - val_loss: 264.2142\n",
      "Epoch 2/50\n",
      "4009/4009 [==============================] - 12s 3ms/step - loss: 152.6113 - val_loss: 32.7049\n",
      "Epoch 3/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 75.2566 - val_loss: 13.8358\n",
      "Epoch 4/50\n",
      "4009/4009 [==============================] - 12s 3ms/step - loss: 61.8027 - val_loss: 7.4170\n",
      "Epoch 5/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 56.3708 - val_loss: 5.8675\n",
      "Epoch 6/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 53.0979 - val_loss: 4.9667\n",
      "Epoch 7/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 49.9334 - val_loss: 5.4559\n",
      "Epoch 8/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 47.5468 - val_loss: 3.7380\n",
      "Epoch 9/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 45.6462 - val_loss: 9.1741\n",
      "Epoch 10/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 44.0619 - val_loss: 3.1813\n",
      "Epoch 11/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 42.0944 - val_loss: 2.1082\n",
      "Epoch 12/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 41.0978 - val_loss: 2.6886\n",
      "Epoch 13/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 39.1800 - val_loss: 5.4274\n",
      "Epoch 14/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 37.9180 - val_loss: 4.7260\n",
      "Epoch 15/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 36.7623 - val_loss: 2.7902\n",
      "Epoch 16/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 35.4403 - val_loss: 6.6901\n",
      "Epoch 17/50\n",
      "4009/4009 [==============================] - 13s 3ms/step - loss: 34.1102 - val_loss: 3.7746\n",
      "Epoch 18/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 33.6989 - val_loss: 3.6373\n",
      "Epoch 19/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 32.4382 - val_loss: 3.8169\n",
      "Epoch 20/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 31.9256 - val_loss: 3.9166\n",
      "Epoch 21/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 30.9253 - val_loss: 5.2098\n",
      "Epoch 22/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 30.5809 - val_loss: 5.5878\n",
      "Epoch 23/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 29.7901 - val_loss: 6.2404\n",
      "Epoch 24/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 28.7542 - val_loss: 5.2099\n",
      "Epoch 25/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 28.1294 - val_loss: 7.0162\n",
      "Epoch 26/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 27.4879 - val_loss: 5.6184\n",
      "Epoch 27/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 27.0425 - val_loss: 6.2708\n",
      "Epoch 28/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 26.5220 - val_loss: 7.2607\n",
      "Epoch 29/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 26.0928 - val_loss: 6.6427\n",
      "Epoch 30/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 25.3599 - val_loss: 7.4072\n",
      "Epoch 31/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 25.0729 - val_loss: 7.7029\n",
      "Epoch 32/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 24.5871 - val_loss: 11.0892\n",
      "Epoch 33/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 24.3660 - val_loss: 12.2138\n",
      "Epoch 34/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 23.8608 - val_loss: 12.5831\n",
      "Epoch 35/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 23.6366 - val_loss: 13.6297\n",
      "Epoch 36/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 22.8420 - val_loss: 15.0624\n",
      "Epoch 37/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 22.9959 - val_loss: 13.4719\n",
      "Epoch 38/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 22.4430 - val_loss: 17.9635\n",
      "Epoch 39/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 21.9776 - val_loss: 16.7404\n",
      "Epoch 40/50\n",
      "4009/4009 [==============================] - 14s 4ms/step - loss: 22.0883 - val_loss: 15.9294\n",
      "Epoch 41/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 21.7700 - val_loss: 16.4671\n",
      "Epoch 42/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 21.4033 - val_loss: 17.3460\n",
      "Epoch 43/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 21.2222 - val_loss: 24.0932\n",
      "Epoch 44/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 20.7849 - val_loss: 25.6877\n",
      "Epoch 45/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 20.7910 - val_loss: 22.7407\n",
      "Epoch 46/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 20.6014 - val_loss: 25.4425\n",
      "Epoch 47/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 20.3459 - val_loss: 26.9636\n",
      "Epoch 48/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 20.6276 - val_loss: 24.5074\n",
      "Epoch 49/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 19.9142 - val_loss: 29.9887\n",
      "Epoch 50/50\n",
      "4009/4009 [==============================] - 14s 3ms/step - loss: 19.8555 - val_loss: 31.4275\n",
      "1003/1003 [==============================] - 2s 1ms/step\n",
      "GRU RMSE: 5.606024593609398\n"
     ]
    }
   ],
   "source": [
    "gru_model = Sequential()\n",
    "gru_model.add(GRU(units=64, return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "gru_model.add(Dropout(0.2))\n",
    "gru_model.add(GRU(units=32, return_sequences=False))\n",
    "gru_model.add(Dropout(0.2))\n",
    "gru_model.add(Dense(1))\n",
    "gru_model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "\n",
    "gru_model.fit(X_train_lstm, y_train, epochs=50, batch_size=32, validation_data=(X_test_lstm, y_test))\n",
    "\n",
    "# Predicting with the GRU\n",
    "y_pred_gru = gru_model.predict(X_test_lstm)\n",
    "print(\"GRU RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_gru)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c841185a",
   "metadata": {},
   "source": [
    "catboost alone stands as the best model across all !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
